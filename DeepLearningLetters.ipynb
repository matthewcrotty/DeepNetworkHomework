{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningLetters.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm3zQHr0gZua"
      },
      "source": [
        "## Selecting Dataset\n",
        "\n",
        "I would like to solve an image classification problem with deep learning. Last year I took Machine Learning from Data and we did a lot of classification work on images of handwritten digits. I don't want to use the same dataset, so I want to work on classifiying letters from images, which should be a harder problem, due to letters having more classes and a larger similarity between letters, such as 'b, d, p, q' and 'm, w, u, n' all having similar physical features.\n",
        "\n",
        "I found EMNIST, which is an extension of the popular MNIST data set of handwritten digits, that includes letters in 28x28 image format. Tensorflow has a dataset loader for EMNIST in the tensorflow_datasets python package. The dataset is described here: https://www.nist.gov/itl/products-and-services/emnist-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMUvtklnhKlB"
      },
      "source": [
        "## Deep Learning Framework Selection\n",
        "\n",
        "Since I am already using the tensorflow dataset library, it would also make sense to use tensorflow for the deep learning portion of my project. I am also using numpy as it allows for easy and fast calculations in my project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMoyH-IuoVNa"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfPuVPceGN9K"
      },
      "source": [
        "Within the tensorflow library, I am using the Keras deep learning api, which is integrated into tensorflow. For most of the refrence for learning the library, I am using the official Tensorflow documentation found here: https://www.tensorflow.org/api_docs/python/tf and here https://www.tensorflow.org/api_docs/python/tf/keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybSTIvR2V8zY"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "The data consists of 103,600 28x28 pixel grayscale images, with 26 classes of images, representing the letters of the alphabet. The dataset info below lists 37 classes, which represent the 26 training classes and 19 test classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXqTRINApG3q",
        "outputId": "9a20b1c1-513d-42f0-c690-ba34c2741567"
      },
      "source": [
        "# Construct a tf.data.Dataset\n",
        "ds_train, ds_dev = tfds.load('emnist/letters', split=['train[:90%]', 'train[90%:]'], as_supervised=True, shuffle_files=True)\n",
        "ds_test, ds_info = tfds.load('emnist/letters', split='test', as_supervised=True, shuffle_files=True, with_info=True)\n",
        "ds_info"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='emnist',\n",
              "    version=3.0.0,\n",
              "    description='The EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19 and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset.\n",
              "\n",
              "Note: Like the original EMNIST data, images provided here are inverted horizontally and rotated 90 anti-clockwise. You can use `tf.transpose` within `ds.map` to convert the images to a human-friendlier format.',\n",
              "    homepage='https://www.nist.gov/itl/products-and-services/emnist-dataset',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=37),\n",
              "    }),\n",
              "    total_num_examples=103600,\n",
              "    splits={\n",
              "        'test': 14800,\n",
              "        'train': 88800,\n",
              "    },\n",
              "    supervised_keys=('image', 'label'),\n",
              "    citation=\"\"\"@article{cohen_afshar_tapson_schaik_2017,\n",
              "        title={EMNIST: Extending MNIST to handwritten letters},\n",
              "        DOI={10.1109/ijcnn.2017.7966217},\n",
              "        journal={2017 International Joint Conference on Neural Networks (IJCNN)},\n",
              "        author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Schaik, Andre Van},\n",
              "        year={2017}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ZdfAVuk8vc"
      },
      "source": [
        "Example images from the dataset. Images are rotated horizontally flipped and rotated 90 degrees. I have also verified that both ds_train and ds_dev contain images from all 26 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "SOq7wl4eWPzw",
        "outputId": "a0d8d9f9-a202-4aaf-9705-cc580d05f286"
      },
      "source": [
        "fig = tfds.show_examples(ds_test, ds_info)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsioVW_dqjD_"
      },
      "source": [
        "However, I do am not running a convolutional nerual network, and do not want to have 28x28 = 784 input nodes, so I will be feature transforming the images into 1d augmented arrays using custom features.\n",
        "\n",
        "Feature 0:\n",
        "Augmented 1\n",
        "\n",
        "Feature 1: Horizontal Symmetry-\n",
        "Comparisons of [0:n/2] to [n/2:n] slices of the image and then averaged for each row\n",
        "\n",
        "Feature 2: Vertical Symmetry-\n",
        "Same as above but with columns.\n",
        "\n",
        "Feature 3: Inverse Intensity-\n",
        "For all pixels (256-grayscale value), averaged among all pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74wRoCbr3u9"
      },
      "source": [
        "def h_sym(image):\n",
        "  sym = 0.0\n",
        "  image = image.T[0]\n",
        "  for i in range(len(image)):\n",
        "    sym += np.average(image[i][0:len(image)//2] - image[i][len(image)//2: len(image)])\n",
        "  return sym/image.shape[0]\n",
        "\n",
        "def v_sym(image):\n",
        "  sym = 0.0\n",
        "  image = image.T[0].T\n",
        "  for i in range(len(image)):\n",
        "    sym += np.average(image[i][0:len(image)//2] - image[i][len(image)//2: len(image)])\n",
        "  return sym/image.shape[0]\n",
        "\n",
        "def intensity(image):\n",
        "  return np.average(image.flatten())\n",
        "\n",
        "def f_transform(image):\n",
        "  image = image.numpy()\n",
        "  return 1.0, h_sym(image), v_sym(image), intensity(image)\n",
        "\n",
        "ds_dev_f = ds_dev.map(lambda data, label: (tf.py_function(f_transform, inp=[data], Tout=[tf.float32, tf.float32, tf.float32, tf.float32]), label))\n",
        "ds_train_f = ds_train.map(lambda data, label: (tf.py_function(f_transform, inp=[data], Tout=[tf.float32, tf.float32, tf.float32, tf.float32]), label))\n",
        "ds_test_f = ds_test.map(lambda data, label: (tf.py_function(f_transform, inp=[data], Tout=[tf.float32, tf.float32, tf.float32, tf.float32]), label))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHCJleSt_E7B"
      },
      "source": [
        "x_train, y_train = [], []\n",
        "for data, label in ds_train_f:\n",
        "  if label in [1, 12, 13, 26]:\n",
        "    x_train.append(data)\n",
        "    y_train.append(label - 1)\n",
        "x_test, y_test = [], []\n",
        "for data, label in ds_test_f:\n",
        "  if label in [1, 12, 13, 26]:\n",
        "    x_test.append(data)\n",
        "    y_test.append(label - 1)\n",
        "x_train = tf.convert_to_tensor(x_train)\n",
        "y_train = tf.convert_to_tensor(y_train, dtype=tf.uint8)\n",
        "x_test = tf.convert_to_tensor(x_test)\n",
        "y_test = tf.convert_to_tensor(y_test, dtype=tf.uint8)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLyRgE2a0rMX",
        "outputId": "934a1700-a66f-4e64-c1c9-7c6e483f12e4"
      },
      "source": [
        "print(len(x_train))\n",
        "print(x_train[0])\n",
        "print(y_train[0])\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12275\n",
            "tf.Tensor([ 1.       38.668365 54.59694  26.397959], shape=(4,), dtype=float32)\n",
            "tf.Tensor(12, shape=(), dtype=uint8)\n",
            "(12275, 4) (12275,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPf-HHpcqK85"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ1FkT9i66L0"
      },
      "source": [
        "# Hyper parameters\n",
        "epochs = 10\n",
        "batches = 1000\n",
        "batch_size = int(len(ds_train)/batches)\n",
        "fc1_nodes, fc2_nodes = 49, 49\n",
        "output_classes = 26"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EosCPcuqlHMN",
        "outputId": "8fa0012b-628a-4c99-f07d-8cb83dd44c94"
      },
      "source": [
        "# Defining forward propogation for the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.Input(shape=(4)),\n",
        "                             tf.keras.layers.Dense(fc1_nodes, activation='relu'),\n",
        "                             tf.keras.layers.Dense(fc2_nodes, activation='relu'),\n",
        "                             tf.keras.layers.Dense(output_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2451\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7353 (Dense)           (None, 49)                245       \n",
            "_________________________________________________________________\n",
            "dense_7354 (Dense)           (None, 49)                2450      \n",
            "_________________________________________________________________\n",
            "dense_7355 (Dense)           (None, 26)                1300      \n",
            "=================================================================\n",
            "Total params: 3,995\n",
            "Trainable params: 3,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3Ehb-eBJMin",
        "outputId": "47e4272f-4a90-47aa-81da-6d214cf9dd4d"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 1.4150 - accuracy: 0.5500\n",
            "Epoch 2/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.8757 - accuracy: 0.6294\n",
            "Epoch 3/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.8554 - accuracy: 0.6365\n",
            "Epoch 4/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.8455 - accuracy: 0.6389\n",
            "Epoch 5/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.8215 - accuracy: 0.6496\n",
            "Epoch 6/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.8071 - accuracy: 0.6524\n",
            "Epoch 7/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.6516\n",
            "Epoch 8/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7968 - accuracy: 0.6522\n",
            "Epoch 9/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7811 - accuracy: 0.6598\n",
            "Epoch 10/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7827 - accuracy: 0.6569\n",
            "Epoch 11/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7804 - accuracy: 0.6542\n",
            "Epoch 12/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7820 - accuracy: 0.6581\n",
            "Epoch 13/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7647 - accuracy: 0.6682\n",
            "Epoch 14/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7657 - accuracy: 0.6637\n",
            "Epoch 15/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7781 - accuracy: 0.6619\n",
            "Epoch 16/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7637 - accuracy: 0.6631\n",
            "Epoch 17/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7719 - accuracy: 0.6630\n",
            "Epoch 18/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7625 - accuracy: 0.6680\n",
            "Epoch 19/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.6645\n",
            "Epoch 20/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7562 - accuracy: 0.6722\n",
            "Epoch 21/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 0.6705\n",
            "Epoch 22/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7636 - accuracy: 0.6643\n",
            "Epoch 23/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 0.6714\n",
            "Epoch 24/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7558 - accuracy: 0.6733\n",
            "Epoch 25/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7497 - accuracy: 0.6722\n",
            "Epoch 26/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.6721\n",
            "Epoch 27/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7534 - accuracy: 0.6708\n",
            "Epoch 28/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.6735\n",
            "Epoch 29/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.6744\n",
            "Epoch 30/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7507 - accuracy: 0.6739\n",
            "Epoch 31/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7493 - accuracy: 0.6705\n",
            "Epoch 32/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.6748\n",
            "Epoch 33/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.6745\n",
            "Epoch 34/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7381 - accuracy: 0.6800\n",
            "Epoch 35/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7438 - accuracy: 0.6764\n",
            "Epoch 36/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7407 - accuracy: 0.6793\n",
            "Epoch 37/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7407 - accuracy: 0.6813\n",
            "Epoch 38/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7456 - accuracy: 0.6758\n",
            "Epoch 39/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7434 - accuracy: 0.6749\n",
            "Epoch 40/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.6792\n",
            "Epoch 41/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.6807\n",
            "Epoch 42/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.6794\n",
            "Epoch 43/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.6811\n",
            "Epoch 44/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7366 - accuracy: 0.6793\n",
            "Epoch 45/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.6795\n",
            "Epoch 46/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7344 - accuracy: 0.6835\n",
            "Epoch 47/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.6846\n",
            "Epoch 48/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6796\n",
            "Epoch 49/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.6792\n",
            "Epoch 50/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.6820\n",
            "Epoch 51/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.6832\n",
            "Epoch 52/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.6865\n",
            "Epoch 53/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.6807\n",
            "Epoch 54/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6829\n",
            "Epoch 55/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.6831\n",
            "Epoch 56/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.6805\n",
            "Epoch 57/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.6832\n",
            "Epoch 58/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.6834\n",
            "Epoch 59/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7259 - accuracy: 0.6871\n",
            "Epoch 60/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6868\n",
            "Epoch 61/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7249 - accuracy: 0.6856\n",
            "Epoch 62/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.6820\n",
            "Epoch 63/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6864\n",
            "Epoch 64/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.6861\n",
            "Epoch 65/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.6841\n",
            "Epoch 66/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7252 - accuracy: 0.6868\n",
            "Epoch 67/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.6824\n",
            "Epoch 68/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7235 - accuracy: 0.6866\n",
            "Epoch 69/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.6852\n",
            "Epoch 70/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.6833\n",
            "Epoch 71/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.6852\n",
            "Epoch 72/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.6869\n",
            "Epoch 73/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7234 - accuracy: 0.6875\n",
            "Epoch 74/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.6883\n",
            "Epoch 75/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.6831\n",
            "Epoch 76/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.6861\n",
            "Epoch 77/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.6894\n",
            "Epoch 78/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7224 - accuracy: 0.6859\n",
            "Epoch 79/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.6891\n",
            "Epoch 80/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.6883\n",
            "Epoch 81/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7212 - accuracy: 0.6864\n",
            "Epoch 82/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6908\n",
            "Epoch 83/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7226 - accuracy: 0.6844\n",
            "Epoch 84/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.6854\n",
            "Epoch 85/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6890\n",
            "Epoch 86/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6884\n",
            "Epoch 87/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.6853\n",
            "Epoch 88/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.6884\n",
            "Epoch 89/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.6881\n",
            "Epoch 90/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7183 - accuracy: 0.6877\n",
            "Epoch 91/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.6855\n",
            "Epoch 92/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6873\n",
            "Epoch 93/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.6847\n",
            "Epoch 94/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7182 - accuracy: 0.6877\n",
            "Epoch 95/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.6892\n",
            "Epoch 96/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.6850\n",
            "Epoch 97/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7211 - accuracy: 0.6864\n",
            "Epoch 98/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.6861\n",
            "Epoch 99/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.6881\n",
            "Epoch 100/100\n",
            "156/156 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.6874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0689831e50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnZNynEGf0RF",
        "outputId": "362f1806-679f-4f5c-899c-b8db58afd0f9"
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7579846978187561, 0.6604166626930237]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb31PO95Cbmr"
      },
      "source": [
        "## Hyperparameter selection\n",
        "\n",
        "To determine the number of epochs to run the model for, I tested a number of different values from 10 to 1000 to determine around when the model stopped improving the accuracy.\n",
        "\n",
        "To determine the batch size, I kinda just estimated that 1000 batches is enough to be considered mini-batches.\n",
        "\n",
        "To determine the optimal hidden layers, I ran the following code overnight to produce the best layer size.\n",
        "\n",
        "I used the adam optimizer, which is built into the keras package since I found that it approached the best accuracy of the model faster than Stochastic Gradient Descent.\n",
        "\n",
        "I didn't use a regularizer since I was not worried about overfitting in this model, but was more worried about underfitting. If I was using a CNN, I would consider using a regularizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dm5TbD0iJpd"
      },
      "source": [
        "# b_acc, b_f1, b_f2 = 0, 0, 0\n",
        "# for f1 in range(1, 100):\n",
        "#   print(f1)\n",
        "#   for f2 in range(1, 100):\n",
        "#     modelt = tf.keras.Sequential([\n",
        "#                                  tf.keras.Input(shape=(4)),\n",
        "#                                  tf.keras.layers.Dense(f1, activation='relu'),\n",
        "#                                  tf.keras.layers.Dense(f2, activation='relu'),\n",
        "#                                  tf.keras.layers.Dense(output_classes, activation='softmax')\n",
        "#                                  ])\n",
        "#     modelt.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "#     modelt.fit(x_train, y_train, batch_size=batch_size, epochs=10, verbose=0)\n",
        "#     output = modelt.evaluate(x_test, y_test, verbose=0)\n",
        "#     if output[1] > b_acc:\n",
        "#       b_f1, b_f2 = f1, f2\n",
        "# print(b_f1, b_f2)"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}